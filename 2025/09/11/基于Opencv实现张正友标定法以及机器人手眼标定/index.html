<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"daiyuejuan.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.23.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"always","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.json","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="介绍opencv、张正友标定法、机器人手眼标定原理。实现基于opencv的工业相机标定。误差在0.1mm以内。">
<meta property="og:type" content="article">
<meta property="og:title" content="基于Opencv实现张正友标定法以及机器人手眼标定">
<meta property="og:url" content="http://daiyuejuan.github.io/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/index.html">
<meta property="og:site_name" content="DaiYueJuan&#39;s Blog">
<meta property="og:description" content="介绍opencv、张正友标定法、机器人手眼标定原理。实现基于opencv的工业相机标定。误差在0.1mm以内。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://daiyuejuan.github.io/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/image-20250915140726971.png">
<meta property="og:image" content="http://daiyuejuan.github.io/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/image-20250915140056602.png">
<meta property="og:image" content="http://daiyuejuan.github.io/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/image-20250915142546676.png">
<meta property="og:image" content="http://daiyuejuan.github.io/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/image-20250915142507063.png">
<meta property="og:image" content="http://daiyuejuan.github.io/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/image-20250915154051347.png">
<meta property="article:published_time" content="2025-09-11T08:01:13.000Z">
<meta property="article:modified_time" content="2025-09-15T09:13:01.875Z">
<meta property="article:author" content="DaiYueJuan">
<meta property="article:tag" content="机器人">
<meta property="article:tag" content="opencv">
<meta property="article:tag" content="相机标定">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://daiyuejuan.github.io/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/image-20250915140726971.png">


<link rel="canonical" href="http://daiyuejuan.github.io/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://daiyuejuan.github.io/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/","path":"2025/09/11/基于Opencv实现张正友标定法以及机器人手眼标定/","title":"基于Opencv实现张正友标定法以及机器人手眼标定"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>基于Opencv实现张正友标定法以及机器人手眼标定 | DaiYueJuan's Blog</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">DaiYueJuan's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Record my study and life.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#OpenCV%E7%AE%80%E8%A6%81%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.</span> <span class="nav-text">OpenCV简要介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#OpenCV-%E6%A0%B8%E5%BF%83%E7%89%B9%E7%82%B9"><span class="nav-number">1.1.</span> <span class="nav-text">OpenCV 核心特点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OpenCV%E4%B8%AD%E7%9A%84%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A"><span class="nav-number">1.2.</span> <span class="nav-text">OpenCV中的相机标定</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#opencv%E4%B8%AD%E6%A0%87%E5%AE%9A%E6%A0%B8%E5%BF%83%E5%87%BD%E6%95%B0"><span class="nav-number">1.2.1.</span> <span class="nav-text">opencv中标定核心函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E5%86%85%E5%8F%82%E5%92%8C%E7%95%B8%E5%8F%98%E7%B3%BB%E6%95%B0%EF%BC%9A"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">计算内参和畸变系数：</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B4%E4%B8%AA%E6%B5%81%E7%A8%8B%EF%BC%9A"><span class="nav-number">1.2.1.1.1.</span> <span class="nav-text">整个流程：</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1-%E8%AE%BE%E7%BD%AE%E6%A0%87%E5%AE%9A%E6%9D%BF%E7%B1%BB%E5%9E%8B"><span class="nav-number">1.2.1.1.1.1.</span> <span class="nav-text">1.设置标定板类型</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-%E4%BB%8E%E8%B7%AF%E5%BE%84%E4%B8%AD%E5%8A%A0%E8%BD%BD%E5%9B%BE%E7%89%87"><span class="nav-number">1.2.1.1.1.2.</span> <span class="nav-text">2.从路径中加载图片</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-%E6%A3%80%E6%B5%8B%E8%A7%92%E7%82%B9-%E2%80%94-%E8%A6%81%E5%85%88%E8%BD%AC%E7%81%B0%E5%BA%A6%E5%9B%BE%E3%80%82"><span class="nav-number">1.2.1.1.1.3.</span> <span class="nav-text">3.检测角点 —-要先转灰度图。</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#4-%E4%BA%9A%E5%83%8F%E7%B4%A0%E7%BA%A7%E8%A7%92%E7%82%B9%E4%BC%98%E5%8C%96%EF%BC%88%E6%8F%90%E9%AB%98%E7%B2%BE%E5%BA%A6%EF%BC%89"><span class="nav-number">1.2.1.1.1.4.</span> <span class="nav-text">4.亚像素级角点优化（提高精度）</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#5-%E6%A0%B9%E6%8D%AE%E6%A0%87%E5%AE%9A%E6%9D%BF%E7%9A%84%E5%8F%82%E6%95%B0%E7%94%9F%E6%88%90%E7%90%86%E6%83%B3%E7%9A%84%E7%89%A9%E7%90%86%E7%82%B9"><span class="nav-number">1.2.1.1.1.5.</span> <span class="nav-text">5.根据标定板的参数生成理想的物理点</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#6-%E8%B0%83%E7%94%A8%E5%87%BD%E6%95%B0"><span class="nav-number">1.2.1.1.1.6.</span> <span class="nav-text">6.调用函数</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#7-%E5%AE%9E%E9%AA%8C%E5%92%8C%E8%AF%AF%E5%B7%AE%E8%AE%A1%E7%AE%97"><span class="nav-number">1.2.1.1.1.7.</span> <span class="nav-text">7.实验和误差计算</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E5%A4%96%E5%8F%82%EF%BC%9A"><span class="nav-number">1.2.1.2.</span> <span class="nav-text">计算外参：</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%9C%BC%E5%9C%A8%E6%89%8B%E4%B8%8A%EF%BC%9A"><span class="nav-number">1.2.1.2.1.</span> <span class="nav-text">眼在手上：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%9C%BC%E5%9C%A8%E6%89%8B%E5%A4%96%EF%BC%9A"><span class="nav-number">1.2.1.2.2.</span> <span class="nav-text">眼在手外：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%E4%B8%8D%E5%90%8C%E5%B8%A6%E6%9D%A5%E7%9A%84%E5%BD%B1%E5%93%8D%EF%BC%9A"><span class="nav-number">1.2.1.2.3.</span> <span class="nav-text">安装方式不同带来的影响：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B4%E4%B8%AA%E6%B5%81%E7%A8%8B%EF%BC%9A-1"><span class="nav-number">1.2.1.2.4.</span> <span class="nav-text">整个流程：</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1-%E8%AE%BE%E7%BD%AE%E6%A0%87%E5%AE%9A%E6%9D%BF%E7%B1%BB%E5%9E%8B-1"><span class="nav-number">1.2.1.2.4.1.</span> <span class="nav-text">1.设置标定板类型</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-%E5%8A%A0%E8%BD%BD%E5%9B%BE%E7%89%87"><span class="nav-number">1.2.1.2.4.2.</span> <span class="nav-text">2.加载图片</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-%E4%BD%BF%E7%94%A8%E4%B9%8B%E5%89%8D%E8%AE%A1%E7%AE%97%E5%87%BA%E6%9D%A5%E7%9A%84%E5%86%85%E5%8F%82%E5%92%8C%E7%95%B8%E5%8F%98%E7%B3%BB%E6%95%B0%E8%BF%9B%E8%A1%8C%E5%9B%BE%E7%89%87%E7%9F%AB%E6%AD%A3"><span class="nav-number">1.2.1.2.4.3.</span> <span class="nav-text">3.使用之前计算出来的内参和畸变系数进行图片矫正</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#4-%E5%AF%B9%E7%9F%AB%E6%AD%A3%E4%B9%8B%E5%90%8E%E7%9A%84%E5%9B%BE%E5%83%8F%E6%A3%80%E6%B5%8B%E8%A7%92%E7%82%B9"><span class="nav-number">1.2.1.2.4.4.</span> <span class="nav-text">4.对矫正之后的图像检测角点</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#5-%E7%94%9F%E6%88%90%E7%90%86%E6%83%B3%E7%9A%84%E7%89%A9%E7%90%86%E7%82%B9"><span class="nav-number">1.2.1.2.4.5.</span> <span class="nav-text">5.生成理想的物理点</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#6-%E5%A4%84%E7%90%86%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%9C%AB%E7%AB%AF%E6%95%B0%E6%8D%AE%E2%80%94%E6%B1%82%E8%A7%A3gripper2base%EF%BC%88%E8%BF%90%E5%8A%A8%E5%88%B0%E5%9B%BA%E5%AE%9A%EF%BC%89"><span class="nav-number">1.2.1.2.4.6.</span> <span class="nav-text">6.处理机器人末端数据—求解gripper2base（运动到固定）</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#7-%E4%BD%BF%E7%94%A8pnp%E7%AE%97%E6%B3%95%E6%B1%82%E8%A7%A3target2cam%E2%80%94%E2%80%93%E6%A0%B8%E5%BF%83%E4%BD%9C%E7%94%A8%E6%98%AF%E8%AE%A1%E7%AE%97-%E2%80%9C%E6%A0%87%E5%AE%9A%E6%9D%BF%EF%BC%88%E7%9B%AE%E6%A0%87%EF%BC%89%E7%9B%B8%E5%AF%B9%E4%BA%8E%E7%9B%B8%E6%9C%BA%E7%9A%84%E4%BD%8D%E5%A7%BF%E2%80%9D%EF%BC%88%E5%8D%B3%E6%A0%87%E5%AE%9A%E6%9D%BF%E5%9C%A8%E7%9B%B8%E6%9C%BA%E5%9D%90%E6%A0%87%E7%B3%BB%E4%B8%8B%E7%9A%84%E6%97%8B%E8%BD%AC%E5%92%8C%E5%B9%B3%E7%A7%BB%E5%85%B3%E7%B3%BB%EF%BC%89"><span class="nav-number">1.2.1.2.4.7.</span> <span class="nav-text">7.使用pnp算法求解target2cam—–核心作用是计算 “标定板（目标）相对于相机的位姿”（即标定板在相机坐标系下的旋转和平移关系）</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#8-%E8%B0%83%E7%94%A8%E5%87%BD%E6%95%B0"><span class="nav-number">1.2.1.2.4.8.</span> <span class="nav-text">8.调用函数</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%A0%87%E5%AE%9A%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D%EF%BC%9A"><span class="nav-number">1.2.1.2.4.9.</span> <span class="nav-text">标定方法介绍：</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%90"><span class="nav-number">1.2.1.2.4.10.</span> <span class="nav-text">误差分析</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="DaiYueJuan"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">DaiYueJuan</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">25</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="/dyj020109@163.com" title="E-Mail → dyj020109@163.com" rel="noopener me"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://daiyuejuan.github.io/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="DaiYueJuan">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="DaiYueJuan's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="基于Opencv实现张正友标定法以及机器人手眼标定 | DaiYueJuan's Blog">
      <meta itemprop="description" content="介绍opencv、张正友标定法、机器人手眼标定原理。实现基于opencv的工业相机标定。误差在0.1mm以内。">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          基于Opencv实现张正友标定法以及机器人手眼标定
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-09-11 16:01:13" itemprop="dateCreated datePublished" datetime="2025-09-11T16:01:13+08:00">2025-09-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-15 17:13:01" itemprop="dateModified" datetime="2025-09-15T17:13:01+08:00">2025-09-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A/" itemprop="url" rel="index"><span itemprop="name">相机标定</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>12k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

            <div class="post-description">介绍opencv、张正友标定法、机器人手眼标定原理。实现基于opencv的工业相机标定。误差在0.1mm以内。</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><span id="more"></span>

<h1 id="OpenCV简要介绍"><a href="#OpenCV简要介绍" class="headerlink" title="OpenCV简要介绍"></a>OpenCV简要介绍</h1><p>OpenCV（全称 <strong>Open Source Computer Vision Library</strong>）是由英特尔发起并由社区维护的<strong>跨平台、开源计算机视觉与机器学习库</strong>，核心目标是为开发者提供通用、高效的计算机视觉解决方案。</p>
<h2 id="OpenCV-核心特点"><a href="#OpenCV-核心特点" class="headerlink" title="OpenCV 核心特点"></a>OpenCV 核心特点</h2><ol>
<li><strong>开源与免费</strong><br>OpenCV 是一个开源项目，任何人都可以免费使用、修改和分发其代码。这意味着你可以根据需要对 OpenCV 进行定制化修改。</li>
<li><strong>跨平台支持</strong><br>OpenCV 支持多个操作系统平台，包括 Windows、Linux、macOS、Android 和 iOS。你可以在各种设备上使用 OpenCV，包括桌面、服务器以及移动设备。</li>
<li><strong>支持多种编程语言</strong><br>OpenCV 提供了多种编程语言的接口，支持 C++、Python、Java、JavaScript 和 MATLAB 等多种编程语言。因此，无论你是 C++ 开发者还是 Python 爱好者，都能轻松使用 OpenCV。</li>
<li><strong>强大的功能库</strong><br>OpenCV 提供了数百个优化的算法，涵盖了计算机视觉和图像处理的方方面面。以下是一些常见的应用：<ul>
<li><strong>图像处理：</strong> 图像滤波、边缘检测、颜色空间转换、形态学操作、特征提取等。</li>
<li><strong>视频分析：</strong> 视频捕捉、运动分析、物体检测与追踪等。</li>
<li><strong>机器学习与人工智能：</strong> OpenCV 集成了深度学习框架，可以进行人脸识别、目标检测、图像分类等。</li>
<li><strong>计算机视觉：</strong> 图像匹配、物体识别、立体视觉、深度图计算等。</li>
</ul>
</li>
<li><strong>高效的性能</strong><br>OpenCV 内置的许多算法都经过高度优化，支持硬件加速（如 Intel 的 TBB、OpenCL、CUDA 等技术），使得它在处理复杂计算时具备高性能，尤其在处理视频流和实时图像分析时非常高效。</li>
</ol>
<h2 id="OpenCV中的相机标定"><a href="#OpenCV中的相机标定" class="headerlink" title="OpenCV中的相机标定"></a>OpenCV中的相机标定</h2><p>经过之前的介绍，我们已经知道了在相机标定中需要求解的有内参、畸变系数、外参。</p>
<h3 id="opencv中标定核心函数"><a href="#opencv中标定核心函数" class="headerlink" title="opencv中标定核心函数"></a>opencv中标定核心函数</h3><h4 id="计算内参和畸变系数："><a href="#计算内参和畸变系数：" class="headerlink" title="计算内参和畸变系数："></a><strong>计算内参和畸变系数：</strong></h4><p>采用基于已知标定物的标定方法：<strong>张正友标定法</strong></p>
<ul>
<li>原理：只需一块平面棋盘格，拍摄多张不同姿态的图片。</li>
<li>步骤：<ol>
<li>检测棋盘格角点（得到二维像素点 (u,v）</li>
<li>知道棋盘格格点的三维世界坐标 (X,Y,0)</li>
<li>建立二维–三维对应关系，先线性估计相机参数</li>
<li>再通过非线性优化（最小化重投影误差）精确求解内参、畸变系数、外参</li>
</ol>
</li>
</ul>
<h5 id="整个流程："><a href="#整个流程：" class="headerlink" title="整个流程："></a><strong>整个流程：</strong></h5><h6 id="1-设置标定板类型"><a href="#1-设置标定板类型" class="headerlink" title="1.设置标定板类型"></a>1.设置标定板类型</h6><p>​	cv::Size 注意在opencv中是角点数量而不是格子数量。例如： 12 * 9 标定板的角点数是 11 *  8</p>
<h6 id="2-从路径中加载图片"><a href="#2-从路径中加载图片" class="headerlink" title="2.从路径中加载图片"></a>2.从路径中加载图片</h6><p>​	用 std::vector &lt; cv::Mat &gt;&amp;  images 保存图片。读取图片的方法为 cv::Mat img &#x3D; cv::imread(fullPath, cv::IMREAD_COLOR);</p>
<h6 id="3-检测角点-—-要先转灰度图。"><a href="#3-检测角点-—-要先转灰度图。" class="headerlink" title="3.检测角点 —-要先转灰度图。"></a>3.检测角点 —-要先转灰度图。</h6><pre><code>CV_EXPORTS_W bool findChessboardCorners( InputArray image, Size patternSize, OutputArray corners,
                                     int flags = CALIB_CB_ADAPTIVE_THRESH + CALIB_CB_NORMALIZE_IMAGE );
</code></pre>
<h6 id="4-亚像素级角点优化（提高精度）"><a href="#4-亚像素级角点优化（提高精度）" class="headerlink" title="4.亚像素级角点优化（提高精度）"></a>4.亚像素级角点优化（提高精度）</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">case HPLPatternType::CHESSBOARD:</span><br><span class="line">		found = cv::findChessboardCorners(gray, patternSize, imagePoints,</span><br><span class="line">			cv::CALIB_CB_ADAPTIVE_THRESH | cv::CALIB_CB_NORMALIZE_IMAGE);</span><br><span class="line"></span><br><span class="line">		if (found) &#123;</span><br><span class="line">			cv::cornerSubPix(gray, imagePoints, cv::Size(11, 11), cv::Size(-1, -1),</span><br><span class="line">				cv::TermCriteria(cv::TermCriteria::EPS + cv::TermCriteria::MAX_ITER, 30, 0.001));</span><br><span class="line">			std::cout &lt;&lt; imagePoints.size() &lt;&lt; &quot;  &quot;;</span><br><span class="line">		&#125;</span><br><span class="line">		break;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>前提</strong>：只有当角点检测成功（<code>found</code>为<code>true</code>）时，才进行后续优化。</p>
</li>
<li><p><strong><code>cv::cornerSubPix</code>功能</strong>：将初步检测到的像素级角点优化到<strong>亚像素级别</strong>（精度可达 0.1 像素以内），这是提高后续标定（如相机内参、手眼矩阵）精度的关键步骤。</p>
</li>
<li><p>参数说明：</p>
<ul>
<li><p><code>gray</code>：输入灰度图（用于计算梯度信息，辅助亚像素定位）。</p>
</li>
<li><p><code>imagePoints</code>：输入输出参数，传入初步检测的角点，输出优化后的亚像素角点。</p>
</li>
<li><p><code>cv::Size(11, 11)</code>：搜索窗口大小（11×11 像素），表示在该范围内寻找更精确的角点位置。</p>
</li>
<li><p><code>cv::Size(-1, -1)</code>：死区大小（此处设为负，表示无死区，即使用整个搜索窗口计算）。</p>
</li>
<li><p>终止条件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TermCriteria</span><br></pre></td></tr></table></figure>

<ul>
<li><code>EPS + MAX_ITER</code>：满足 “精度阈值” 或 “最大迭代次数” 任一条件即停止优化。</li>
<li><code>30</code>：最大迭代次数（最多迭代 30 次）。</li>
<li><code>0.001</code>：精度阈值（当角点位置变化小于 0.001 像素时，停止优化）。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h6 id="5-根据标定板的参数生成理想的物理点"><a href="#5-根据标定板的参数生成理想的物理点" class="headerlink" title="5.根据标定板的参数生成理想的物理点"></a>5.根据标定板的参数生成理想的<strong>物理点</strong></h6><p>​	核心是为了让生成的<strong>三维物体点坐标顺序</strong>与<strong>图像中检测到的角点顺序</strong>保持一致，确保后续标定过程中 “三维物体点” 与 “二维图像点” 能正确匹配。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">int rows = boardSize.height;</span><br><span class="line">int cols = boardSize.width;</span><br><span class="line"></span><br><span class="line">case HPLPatternType::CHESSBOARD:</span><br><span class="line">		// 生成 (j, i) 格子对应的三维坐标 (单位：size)</span><br><span class="line">		for (size_t i = 0; i &lt; rows; ++i) &#123;</span><br><span class="line">			for (int j = 0; j &lt; cols; ++j) &#123;</span><br><span class="line">				m_objPts.emplace_back(j * spacing, i * spacing, 0);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		break;</span><br></pre></td></tr></table></figure>

<p>​	双重循环即可，需要注意的是：</p>
<p>​		<strong>1.棋盘格的坐标系统定义</strong></p>
<p>​		标定板（棋盘格）的三维坐标系通常这样定义：原点（0,0,0）设在棋盘格<strong>左上角的第一个内角点</strong>；<strong>x 轴</strong>沿水平方向（从左到右，对应 “列方向”）；<strong>y 轴</strong>沿垂直方向（从上到下，对应 “行方向”）；<strong>z 轴</strong>垂直于标定板平面（所有点 z&#x3D;0，因为棋盘格是平面）。</p>
<p>​		<strong>2.循环顺序与点的排列顺序</strong></p>
<p>​		代码中：外层循环<code>i</code>：遍历棋盘格的<strong>行数</strong>（<code>rows = boardSize.height</code>），对应 y 轴方向（从上到下）；</p>
<p>​				内层循环<code>j</code>：遍历棋盘格的<strong>列数</strong>（<code>cols = boardSize.width</code>），对应 x 轴方向（从左到右）。</p>
<p>​				生成的三维坐标是 <code>(j * spacing, i * spacing, 0)</code>，即：</p>
<p>​				对于第<code>i</code>行、第<code>j</code>列的内角点，x 坐标由列索引<code>j</code>决定（水平方向），y 坐标由行索引<code>i</code>决定（垂直方向）。</p>
<p>​				这样生成的<code>m_objPts</code>中，点的顺序是 <strong>“按行排列”</strong>：先排完第 0 行的所有列（j 从 0 到 cols-1），再排第 1 行的所有列，以此类推。</p>
<p>​		<strong>3. 与图像角点检测顺序匹配</strong></p>
<p>​		关键原因是：<strong>图像中检测到的角点顺序也是 “按行排列” 的</strong>。<br>在之前的<code>findChessboardCorners</code>函数中，检测到的<code>imagePoints</code>（二维图像角点）顺序是<strong>从左到右、从上到下</strong>（先扫完一行，再扫下一行），与上述三维物体点的排列顺序完全一致。</p>
<p>​		如果循环顺序反过来（外层 j、内层 i），会导致三维物体点 “按列排列”，与二维图像点的顺序不匹配，后续标定（如<code>calibrateCamera</code>）时会因 “点对应错误” 导致结果失效。</p>
<p>​		<strong>总结</strong></p>
<p>​		循环的内外层顺序（先 i 后 j）是为了保证：<strong>三维物体点的排列顺序 ↔ 二维图像角点的检测顺序</strong> 严格一致。<br>​		这种一致性是相机标定、位姿估计的核心前提 —— 只有每个二维图像点都能准确对应到唯一的三维物体点，才能通过几何关系求解相机内参或位姿矩阵。</p>
<h6 id="6-调用函数"><a href="#6-调用函数" class="headerlink" title="6.调用函数"></a>6.调用函数</h6><p>主要使用的函数： </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** @overload */</span></span><br><span class="line"><span class="function">CV_EXPORTS_W <span class="type">double</span> <span class="title">calibrateCamera</span><span class="params">( InputArrayOfArrays objectPoints,</span></span></span><br><span class="line"><span class="params"><span class="function">                                     InputArrayOfArrays imagePoints, Size imageSize,</span></span></span><br><span class="line"><span class="params"><span class="function">                                     InputOutputArray cameraMatrix, InputOutputArray distCoeffs,</span></span></span><br><span class="line"><span class="params"><span class="function">                                     OutputArrayOfArrays rvecs, OutputArrayOfArrays tvecs,</span></span></span><br><span class="line"><span class="params"><span class="function">                                     <span class="type">int</span> flags = <span class="number">0</span>, TermCriteria criteria = TermCriteria(</span></span></span><br><span class="line"><span class="params"><span class="function">                                        TermCriteria::COUNT + TermCriteria::EPS, <span class="number">30</span>, DBL_EPSILON) )</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 我的调用</span></span><br><span class="line"><span class="type">double</span> rms = cv::<span class="built_in">calibrateCamera</span>(m_objectPoints, m_imagePoints, m_imageSize,</span><br><span class="line">    cameraMatrix, distCoeffs, rvecs, tvecs, cv::CALIB_FIX_K3);</span><br></pre></td></tr></table></figure>

<p>主要功能是通过标定板图像的特征点，求解相机的内参矩阵（Camera Matrix）和畸变系数（Distortion Coefficients），并评估标定精度。</p>
<ul>
<li>参数说明：<ul>
<li><code>m_objectPoints</code>&#x2F;<code>m_imagePoints</code>：三维物体点和二维图像点的对应关系（核心输入）。</li>
<li><code>m_imageSize</code>：图像尺寸（宽 x 高），用于辅助计算。</li>
<li><code>cameraMatrix</code>&#x2F;<code>distCoeffs</code>：输出参数，存储求解得到的内参矩阵和畸变系数。</li>
<li><code>rvecs</code>&#x2F;<code>tvecs</code>：输出参数，存储每幅图像对应的旋转 &#x2F; 平移向量。</li>
<li><code>cv::CALIB_FIX_K3</code>：标定标志，含义是 “固定畸变系数中的 k3 为 0”（简化模型，适用于畸变较小的场景）。</li>
</ul>
</li>
<li>返回值<code>rms</code>：重投影误差的均方根（Root Mean Square），是评估标定精度的核心指标（值越小越好，通常希望小于 1 像素）。</li>
</ul>
<h6 id="7-实验和误差计算"><a href="#7-实验和误差计算" class="headerlink" title="7.实验和误差计算"></a>7.实验和误差计算</h6><p><img src="/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/image-20250915140726971.png" alt="image-20250915140726971"></p>
<p>可以求总的RMS 和每张图片的RMS</p>
<p><img src="/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/image-20250915140056602.png" alt="image-20250915140056602"></p>
<h4 id="计算外参："><a href="#计算外参：" class="headerlink" title="计算外参："></a><strong>计算外参：</strong></h4><p>根据之前的介绍我们知道，外参就是描述相机在世界坐标系下的位姿，在机器人手眼标定中，其实就是描述相机在机器人基座标系下的位姿。</p>
<p>而在机器人手眼标定中，又分为两种：眼在手上、眼在手外。</p>
<p><img src="/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/image-20250915142546676.png" alt="image-20250915142546676"></p>
<h5 id="眼在手上："><a href="#眼在手上：" class="headerlink" title="眼在手上："></a>眼在手上：</h5><p>相机直接安装在机器人末端执行器上，与机械臂同步运动。此时，相机“看到”的场景会随着机械臂的移动而变化。</p>
<p><img src="/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/image-20250915142507063.png" alt="image-20250915142507063"></p>
<h5 id="眼在手外："><a href="#眼在手外：" class="headerlink" title="眼在手外："></a>眼在手外：</h5><p>相机安装在机器人之外的一个固定地方。不会随着机器人运动而运动。</p>
<p><img src="/2025/09/11/%E5%9F%BA%E4%BA%8EOpencv%E5%AE%9E%E7%8E%B0%E5%BC%A0%E6%AD%A3%E5%8F%8B%E6%A0%87%E5%AE%9A%E6%B3%95%E4%BB%A5%E5%8F%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%89%8B%E7%9C%BC%E6%A0%87%E5%AE%9A/image-20250915154051347.png" alt="image-20250915154051347"></p>
<h5 id="安装方式不同带来的影响："><a href="#安装方式不同带来的影响：" class="headerlink" title="安装方式不同带来的影响："></a><strong>安装方式不同带来的影响：</strong></h5><p>手眼标定的核心是建立 “相机坐标系” 与 “机器人基坐标系” 的转换关系，但相机与机器人的安装方式会改变位姿数据的物理意义：</p>
<ul>
<li><strong><code>EyeInHand</code>（眼在手上）</strong>：<br>相机固定在机器人末端（夹爪）上，随机器人一起运动。此时，标定板固定在外部（如桌面），相机拍摄的是固定的标定板。<br>机器人提供的位姿数据（<code>robotPoseList</code>）是 “<strong>夹爪坐标系 → 机器人基坐标系</strong>” 的转换（<code>R_gripper2base, t_gripper2base</code>），这正是手眼标定需要的位姿关系（因为相机与夹爪刚性连接，两者相对位姿不变）。</li>
<li><strong><code>EyeToHand</code>（眼在手外）</strong>：<br>相机固定在外部（如支架上），不随机器人运动。此时，标定板固定在机器人末端（夹爪）上，随机器人一起运动。<br>机器人提供的位姿数据（<code>robotPoseList</code>）仍是 “<strong>夹爪坐标系 → 机器人基坐标系</strong>” 的转换，但手眼标定需要的是 “<strong>机器人基坐标系 → 夹爪坐标系</strong>” 的转换（因为标定板随夹爪运动，相机观察的是运动的标定板）。</li>
</ul>
<p>手眼标定算法（如<code>cv::calibrateHandEye</code>）要求输入的位姿数据必须满足 “<strong>运动端与固定端的对应关系</strong>”：</p>
<ul>
<li>对于<code>EyeInHand</code>：运动端是 “夹爪 + 相机”，固定端是 “标定板”，需要 “夹爪→基” 的位姿；</li>
<li>对于<code>EyeToHand</code>：运动端是 “夹爪 + 标定板”，固定端是 “相机”，需要 “基→夹爪” 的位姿（与机器人原始数据方向相反）。</li>
</ul>
<p>因此，<code>EyeToHand</code>需要对原始位姿做<strong>逆变换</strong>，将 “夹爪→基” 转换为 “基→夹爪”：</p>
<p><strong>旋转矩阵<code>R</code>的处理（转置）</strong></p>
<p>旋转矩阵的 “逆变换” 等价于 “转置”（因为旋转矩阵是正交矩阵，其逆矩阵 &#x3D; 转置矩阵）：</p>
<ul>
<li>原始旋转矩阵<code>R_gripper2base</code>：表示 “夹爪→基” 的旋转；</li>
<li>逆变换后<code>Rt = R.t()</code>：表示 “基→夹爪” 的旋转（即<code>R_base2gripper</code>）。</li>
</ul>
<p><strong>平移向量<code>t</code>的处理（反向变换）</strong></p>
<p>平移向量的逆变换需要结合旋转矩阵：</p>
<ul>
<li>原始平移向量<code>t_gripper2base</code>：表示 “夹爪原点在基坐标系中的坐标”；</li>
<li>逆变换后<code>t_inv = -Rt * t</code>：表示 “基原点在夹爪坐标系中的坐标”（即<code>t_base2gripper</code>）。</li>
</ul>
<p>推导逻辑：若<code>P_base = R * P_gripper + t</code>（夹爪坐标→基坐标），则逆变换为<code>P_gripper = R.t() * (P_base - t) = R.t() * P_base - R.t() * t</code>，因此 “基→夹爪” 的平移向量为<code>-R.t() * t</code>。</p>
<p><strong>总结</strong></p>
<p>两种安装方式下对<code>R</code>和<code>t</code>的处理不同，本质是为了<strong>统一位姿数据的方向</strong>，确保输入到手眼标定算法中的位姿关系符合 <strong>“运动端→固定端”</strong> 的逻辑：</p>
<ul>
<li><code>EyeInHand</code>：直接使用 “夹爪→基” 的位姿（与运动方向一致）；</li>
<li><code>EyeToHand</code>：通过逆变换将 “夹爪→基” 转为 “基→夹爪” 的位姿（修正方向以匹配运动逻辑）。</li>
</ul>
<h5 id="整个流程：-1"><a href="#整个流程：-1" class="headerlink" title="整个流程："></a>整个流程：</h5><h6 id="1-设置标定板类型-1"><a href="#1-设置标定板类型-1" class="headerlink" title="1.设置标定板类型"></a>1.设置标定板类型</h6><h6 id="2-加载图片"><a href="#2-加载图片" class="headerlink" title="2.加载图片"></a>2.加载图片</h6><h6 id="3-使用之前计算出来的内参和畸变系数进行图片矫正"><a href="#3-使用之前计算出来的内参和畸变系数进行图片矫正" class="headerlink" title="3.使用之前计算出来的内参和畸变系数进行图片矫正"></a>3.使用之前计算出来的内参和畸变系数进行图片矫正</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">	// 利用标定好的内参，对输入的相片进行图像校正（去除畸变，还原真实世界视角）</span><br><span class="line">	std::cout &lt;&lt; &quot;UndistoredImage:&quot; &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">	for (int i = 0; i &lt; m_vMatImages.size(); i++)</span><br><span class="line">	&#123;</span><br><span class="line">		cv::Mat Matundistorted;</span><br><span class="line">		undistort(m_vMatImages[i], Matundistorted, m_cameraMatrix, m_distCoeffs);</span><br><span class="line">		m_vMatundistortedImg.push_back(Matundistorted);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h6 id="4-对矫正之后的图像检测角点"><a href="#4-对矫正之后的图像检测角点" class="headerlink" title="4.对矫正之后的图像检测角点"></a>4.对矫正之后的图像检测角点</h6><h6 id="5-生成理想的物理点"><a href="#5-生成理想的物理点" class="headerlink" title="5.生成理想的物理点"></a>5.生成理想的物理点</h6><h6 id="6-处理机器人末端数据—求解gripper2base（运动到固定）"><a href="#6-处理机器人末端数据—求解gripper2base（运动到固定）" class="headerlink" title="6.处理机器人末端数据—求解gripper2base（运动到固定）"></a>6.处理机器人末端数据—求解gripper2base（运动到固定）</h6><p>注意：这里要根据安装方式的不同去不同地处理  参考上面的“ 安装方式不同带来的影响”</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">// 1. 提取平移向量</span><br><span class="line">cv::Mat tvec = (cv::Mat_&lt;double&gt;(3, 1) &lt;&lt; pose.x(), pose.y(), pose.z());</span><br><span class="line"></span><br><span class="line">// 2. 提取欧拉角并转为 Mat  单位：角度</span><br><span class="line">cv::Mat euler = (cv::Mat_&lt;double&gt;(1, 3) &lt;&lt; pose.r1(), pose.r2(), pose.r3());</span><br><span class="line">//std::cout &lt;&lt; &quot;Pose &quot; &lt;&lt; i &lt;&lt; &quot;: &quot;</span><br><span class="line">//	&lt;&lt; &quot;T=(&quot; &lt;&lt; tvec &lt;&lt; &quot;),, &quot;</span><br><span class="line">//	&lt;&lt; &quot;euler=(&quot; &lt;&lt; euler &lt;&lt; &quot;),,&quot; &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">// 3. 计算旋转矩阵</span><br><span class="line">cv::Mat rmat = eulerAngleToRotateMatrix(euler);</span><br><span class="line"></span><br><span class="line">//std::cout &lt;&lt; &quot;R=(&quot; &lt;&lt; rmat &lt;&lt; &quot;)&quot; &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">cv::Mat R, Rt, t, t_inv;</span><br><span class="line"></span><br><span class="line">switch (m_InstallType)&#123;</span><br><span class="line">case HPLEyeHandType::EyeInHand:</span><br><span class="line">	// 眼在手上</span><br><span class="line">	m_Vec_t_gripper2base.push_back(tvec);</span><br><span class="line">	m_Vec_R_gripper2base.push_back(rmat);</span><br><span class="line">	break;</span><br><span class="line"></span><br><span class="line">case HPLEyeHandType::EyeToHand:</span><br><span class="line">	// 眼在手外--对旋转矩阵进行转置；-对平移矩阵进行一次变换</span><br><span class="line">	R = rmat;</span><br><span class="line">	// 对旋转矩阵进行转置</span><br><span class="line">	Rt = R.t();</span><br><span class="line">	m_Vec_R_gripper2base.push_back(Rt);</span><br><span class="line"></span><br><span class="line">	// 读取末端平移矩阵</span><br><span class="line">	t = tvec;</span><br><span class="line">	t_inv = -Rt * t;</span><br><span class="line">	//std::cout &lt;&lt; &quot;-Rt*t:&quot; &lt;&lt; t_inv &lt;&lt; std::endl;</span><br><span class="line">	m_Vec_t_gripper2base.push_back(t_inv);</span><br><span class="line">	break;</span><br></pre></td></tr></table></figure>



<h6 id="7-使用pnp算法求解target2cam—–核心作用是计算-“标定板（目标）相对于相机的位姿”（即标定板在相机坐标系下的旋转和平移关系）"><a href="#7-使用pnp算法求解target2cam—–核心作用是计算-“标定板（目标）相对于相机的位姿”（即标定板在相机坐标系下的旋转和平移关系）" class="headerlink" title="7.使用pnp算法求解target2cam—–核心作用是计算 “标定板（目标）相对于相机的位姿”（即标定板在相机坐标系下的旋转和平移关系）"></a>7.使用pnp算法求解target2cam—–核心作用是<strong>计算 “标定板（目标）相对于相机的位姿”</strong>（即标定板在相机坐标系下的旋转和平移关系）</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CV_EXPORTS_W bool solvePnP( InputArray objectPoints, InputArray imagePoints,</span><br><span class="line">                            InputArray cameraMatrix, InputArray distCoeffs,</span><br><span class="line">                            OutputArray rvec, OutputArray tvec,</span><br><span class="line">                            bool useExtrinsicGuess = false, int flags = SOLVEPNP_ITERATIVE );</span><br></pre></td></tr></table></figure>

<p><strong>PnP算法</strong></p>
<p>PnP（Perspective-n-Point，<strong>透视 n 点问题</strong>）是计算机视觉中的核心算法，核心逻辑是：<br><strong>已知相机内参的前提下，通过 “n 个 3D 世界坐标已知的点” 和它们对应的 “2D 图像像素坐标”，求解 3D 目标（如标定板）相对于相机的位姿（旋转矩阵 R + 平移向量 t）。</strong></p>
<p>简单理解：通过图像中 “已知 3D 位置的点”，反推 “相机看目标的角度（R）” 和 “相机到目标的距离（t）”。</p>
<p><strong>PnP 算法的核心好处</strong></p>
<ol>
<li><strong>精度高</strong><br>支持迭代法（如代码中 <code>SOLVEPNP_ITERATIVE</code>）、鲁棒法（如 <code>solvePnPRansac</code> 抗外点），能有效抑制噪声和少量误匹配点的干扰，适合高精度位姿测量（如机器人视觉引导）。</li>
<li><strong>依赖条件少</strong><br>仅需两个核心输入：① 相机内参（标定后可复用）；② 至少 4 个 3D-2D 点对（n≥4，实际用标定板的多个角点进一步提升精度），无需额外设备。</li>
<li><strong>通用性强</strong><br>广泛应用于相机标定、手眼标定、AR&#x2F;VR（虚拟物体对齐现实）、目标跟踪、机器人抓取等场景，是视觉位姿估计的 “基础工具”。</li>
<li><strong>工程化友好</strong><br>OpenCV 等库已优化实现，接口简洁、运行效率高，支持实时或批量处理（如代码中循环处理多帧图像的位姿）。</li>
</ol>
<h6 id="8-调用函数"><a href="#8-调用函数" class="headerlink" title="8.调用函数"></a>8.调用函数</h6><p><code>cv::calibrateHandEye</code>是 OpenCV 中用于<strong>机器人手眼标定</strong>的核心函数。它通过多组位姿数据，求解出相机与夹爪的相对位姿，为机器人视觉引导（如抓取、定位）提供坐标映射的关键参数。</p>
<p>手眼标定的本质是建立 “相机” 与 “机器人末端” 的刚性转换关系。当机器人带动相机（或相机固定、机器人末端带动靶标）运动时，通过记录多组位姿，该函数可计算出：<strong>相机坐标系 → 机器人末端（夹爪）坐标系的旋转矩阵和平移向量</strong>，从而实现 “相机识别的目标坐标” 到 “机器人可执行的坐标” 的转换。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CV_EXPORTS_W void calibrateHandEye( InputArrayOfArrays R_gripper2base, InputArrayOfArrays t_gripper2base,</span><br><span class="line">                                    InputArrayOfArrays R_target2cam, InputArrayOfArrays t_target2cam,</span><br><span class="line">                                    OutputArray R_cam2gripper, OutputArray t_cam2gripper,</span><br><span class="line">                                    HandEyeCalibrationMethod method=CALIB_HAND_EYE_TSAI );</span><br></pre></td></tr></table></figure>



<p>只需要将前面得到的gripper2base和target2cam参数放到函数中去调用即可。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CV_EXPORTS_W void calibrateHandEye(</span><br><span class="line">    InputArrayOfArrays R_gripper2base,  // 输入：夹爪到机器人基坐标系的旋转矩阵集合</span><br><span class="line">    InputArrayOfArrays t_gripper2base,  // 输入：夹爪到机器人基坐标系的平移向量集合</span><br><span class="line">    InputArrayOfArrays R_target2cam,    // 输入：靶标到相机坐标系的旋转矩阵集合</span><br><span class="line">    InputArrayOfArrays t_target2cam,    // 输入：靶标到相机坐标系的平移向量集合</span><br><span class="line">    OutputArray R_cam2gripper,          // 输出：相机到夹爪坐标系的旋转矩阵</span><br><span class="line">    OutputArray t_cam2gripper,          // 输出：相机到夹爪坐标系的平移向量</span><br><span class="line">    HandEyeCalibrationMethod method = CALIB_HAND_EYE_TSAI  // 标定方法（默认TSAI）</span><br><span class="line">);</span><br></pre></td></tr></table></figure>



<h6 id="标定方法介绍："><a href="#标定方法介绍：" class="headerlink" title="标定方法介绍："></a>标定方法介绍：</h6><table>
<thead>
<tr>
<th>方法枚举值</th>
<th>核心原理</th>
<th>优点</th>
<th>缺点</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><code>CALIB_HAND_EYE_TSAI</code></td>
<td>分离求解旋转与平移：先通过矩阵运算求旋转，再用最小二乘法求平移</td>
<td>计算效率高，精度均衡，抗中等噪声能力较好，工程实用性强</td>
<td>平移误差依赖旋转结果，易累积；对严重噪声或位姿分布不均敏感</td>
<td>常规工业场景（如装配、搬运），中等精度需求，对实时性有一定要求</td>
</tr>
<tr>
<td><code>CALIB_HAND_EYE_PARK</code></td>
<td>基于四元数表示旋转，构建线性方程组同时求解旋转与平移的近似解</td>
<td>数学模型简单，计算速度快，适合快速验证</td>
<td>对噪声极敏感，精度较低；位姿数据不足时易漂移</td>
<td>快速原型验证，低精度场景（如误差允许＞1mm），对速度要求高的场景</td>
</tr>
<tr>
<td><code>CALIB_HAND_EYE_HORAUD</code></td>
<td>用对偶四元数统一表示旋转与平移，通过特征值分解同时优化两者</td>
<td>理论精度高，抗噪声能力较强，避免误差累积</td>
<td>计算复杂度高（特征值分解耗时），对上位姿数量和分布要求高（需≥10 组）</td>
<td>高精度场景（如精密装配、微电子封装），离线标定且位姿数据充足</td>
</tr>
<tr>
<td><code>CALIB_HAND_EYE_ANDREFF</code></td>
<td>基于非线性优化（如 Levenberg-Marquardt），构建联合误差函数迭代求解最优解</td>
<td>精度最高，对噪声和位姿分布不均容忍度好，无近似简化</td>
<td>计算量最大（迭代耗时），需大量高质量位姿数据才能稳定收敛</td>
<td>超高精度任务（如光学检测、精密定位），离线标定且对精度要求严苛的场景</td>
</tr>
</tbody></table>
<p>主要采用TSAI</p>
<h6 id="误差分析"><a href="#误差分析" class="headerlink" title="误差分析"></a>误差分析</h6><p>1.会进行多种标定方法的计算，如果有很大的误差，不同方法算出来的值会相差很多。</p>
<p>2.重投影误差分析</p>
<p>3.实际走点</p>
<p>4.通过量化 “靶标在机器人基坐标系下的位姿一致性” 来评估标定结果的可靠性。</p>
<p>核心逻辑是：<strong>若手眼标定准确，靶标在机器人基坐标系下的位姿应保持稳定（变化极小）</strong>，因此通过计算多组位姿的 “平移偏差” 和 “旋转偏差” 来衡量标定精度。</p>
<p><strong>误差计算的核心原理</strong></p>
<p>手眼标定的本质是建立 “相机→夹爪” 的变换关系（矩阵<code>X</code>）。在标定过程中，无论相机是 “眼在手上”（随夹爪运动）还是 “眼在手外”（固定），<strong>靶标相对机器人基坐标系的位姿理论上应保持不变</strong>（因靶标要么固定在外部，要么随夹爪刚性连接）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">std::string HPLCaliAlgoOpenCV::HandEyeCalibrationError()</span><br><span class="line">&#123;</span><br><span class="line">	std::string error;</span><br><span class="line">	if (m_Vec_R_gripper2base.size() != m_Vec_t_gripper2base.size() ||</span><br><span class="line">		m_Vec_R_target2cam.size() != m_Vec_t_target2cam.size() ||</span><br><span class="line">		m_Vec_R_gripper2base.size() != m_Vec_R_target2cam.size())&#123;</span><br><span class="line">		std::cerr &lt;&lt; &quot;Hand-eye calibration input size mismatch!&quot; &lt;&lt; std::endl;</span><br><span class="line">		return &quot;Hand-eye calibration input size mismatch!&quot;;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// 构造手眼变换矩阵 X = [R | t]</span><br><span class="line">	cv::Mat X = cv::Mat::eye(4, 4, CV_64F);</span><br><span class="line">	m_HandEyeResult_RVec.copyTo(X(cv::Rect(0, 0, 3, 3)));</span><br><span class="line">	m_HandEyeResult_TVec.copyTo(X(cv::Rect(3, 0, 1, 3)));</span><br><span class="line"></span><br><span class="line">	std::vector&lt;cv::Mat&gt; vec_target_in_base;</span><br><span class="line">	std::vector&lt;cv::Mat&gt; vec_R;</span><br><span class="line"></span><br><span class="line">	for (size_t i = 0; i &lt; m_Vec_R_gripper2base.size(); ++i)</span><br><span class="line">	&#123;</span><br><span class="line">		// T_e^b</span><br><span class="line">		cv::Mat T_e_b = cv::Mat::eye(4, 4, CV_64F);</span><br><span class="line">		m_Vec_R_gripper2base[i].copyTo(T_e_b(cv::Rect(0, 0, 3, 3)));</span><br><span class="line">		m_Vec_t_gripper2base[i].copyTo(T_e_b(cv::Rect(3, 0, 1, 3)));</span><br><span class="line"></span><br><span class="line">		// T_t^c</span><br><span class="line">		cv::Mat T_t_c = cv::Mat::eye(4, 4, CV_64F);</span><br><span class="line">		m_Vec_R_target2cam[i].copyTo(T_t_c(cv::Rect(0, 0, 3, 3)));</span><br><span class="line">		m_Vec_t_target2cam[i].copyTo(T_t_c(cv::Rect(3, 0, 1, 3)));</span><br><span class="line"></span><br><span class="line">		// 计算 T_t^b = T_e^b * X * T_t^c</span><br><span class="line">		cv::Mat T_t_b = T_e_b * X * T_t_c;</span><br><span class="line"></span><br><span class="line">		vec_target_in_base.push_back(T_t_b);</span><br><span class="line">		vec_R.push_back(T_t_b(cv::Rect(0, 0, 3, 3)).clone());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// 计算平移误差（平均值 + RMS）</span><br><span class="line">	cv::Mat mean_t = cv::Mat::zeros(3, 1, CV_64F);</span><br><span class="line">	for (const auto&amp; T : vec_target_in_base)</span><br><span class="line">		mean_t += T(cv::Rect(3, 0, 1, 3));</span><br><span class="line">	mean_t /= (double)vec_target_in_base.size();</span><br><span class="line"></span><br><span class="line">	double rms = 0.0;</span><br><span class="line">	for (const auto&amp; T : vec_target_in_base)</span><br><span class="line">	&#123;</span><br><span class="line">		cv::Mat diff = T(cv::Rect(3, 0, 1, 3)) - mean_t;</span><br><span class="line">		rms += cv::norm(diff);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	rms /= vec_target_in_base.size();</span><br><span class="line"></span><br><span class="line">	// --- 旋转误差 ---</span><br><span class="line">	cv::Mat rvec_mean = cv::Mat::zeros(3, 1, CV_64F);</span><br><span class="line">	for (const auto&amp; R : vec_R)</span><br><span class="line">	&#123;</span><br><span class="line">		cv::Mat rvec;</span><br><span class="line">		cv::Rodrigues(R, rvec);</span><br><span class="line">		rvec_mean += rvec;</span><br><span class="line">	&#125;</span><br><span class="line">	rvec_mean /= static_cast&lt;double&gt;(vec_R.size());</span><br><span class="line"></span><br><span class="line">	cv::Mat R_mean;</span><br><span class="line">	cv::Rodrigues(rvec_mean, R_mean);</span><br><span class="line"></span><br><span class="line">	double total_rot_error_deg = 0.0;</span><br><span class="line">	for (const auto&amp; R : vec_R)</span><br><span class="line">	&#123;</span><br><span class="line">		cv::Mat R_diff = R_mean.t() * R;</span><br><span class="line">		double angle_rad = std::acos(std::min(1.0, std::max(-1.0, (cv::trace(R_diff)[0] - 1.0) / 2.0)));</span><br><span class="line">		double angle_deg = angle_rad * 180.0 / CV_PI;</span><br><span class="line">		total_rot_error_deg += angle_deg;</span><br><span class="line">	&#125;</span><br><span class="line">	double avg_rot_error_deg = total_rot_error_deg / vec_R.size();</span><br><span class="line"></span><br><span class="line">	std::ostringstream oss;</span><br><span class="line">	oss &lt;&lt; &quot;RMS translation error = &quot; &lt;&lt; rms &lt;&lt; &quot; mm\n&quot;</span><br><span class="line">		&lt;&lt; &quot;Average rotation error = &quot; &lt;&lt; avg_rot_error_deg &lt;&lt; &quot; deg&quot;;</span><br><span class="line">	</span><br><span class="line">	error = oss.str();</span><br><span class="line">	return error;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/" rel="tag"># 机器人</a>
              <a href="/tags/opencv/" rel="tag"># opencv</a>
              <a href="/tags/%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A/" rel="tag"># 相机标定</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/09/11/%E8%A7%A3%E5%86%B3-Typora-%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87%E8%B7%AF%E5%BE%84%E4%B8%8E-Hexo-%E4%B8%8D%E5%85%BC%E5%AE%B9/" rel="prev" title="解决 Typora 插入图片路径与 Hexo 不兼容">
                  <i class="fa fa-angle-left"></i> 解决 Typora 插入图片路径与 Hexo 不兼容
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">DaiYueJuan</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">52k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">47 分钟</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
